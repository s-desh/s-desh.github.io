<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">








    






<link rel="icon" type="image/ico" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="http://localhost:1313/android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/apple-touch-icon.png">

<meta name="description" content=""/>


<meta name="fediverse:creator" content="@username@instance.url">


<title>
    
    Whole-body control of an aerial manipulator with reinforcement learning | Shlok Deshmukh
    
</title>

<link rel="canonical" href="http://localhost:1313/project/thesis/"/>

<meta property="og:url" content="http://localhost:1313/project/thesis/">
  <meta property="og:site_name" content="Shlok Deshmukh">
  <meta property="og:title" content="Whole-body control of an aerial manipulator with reinforcement learning">
  <meta property="og:description" content="Master Thesis">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="project">
    <meta property="article:published_time" content="2025-08-27T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-08-27T00:00:00+00:00">
    <meta property="article:tag" content="Learning">
    <meta property="article:tag" content="Control">
    <meta property="article:tag" content="Aerial-Robotics">












<link rel="stylesheet" href="/assets/combined.min.4702c9c0e4e4b1cf41129fc191e74bd6232a79a7b333ec6b67c55dac36080576.css" media="all">











    




</head>







<body class="light">

  <div class="content">
    <header>
      

<div class="header">

    

    <h1 class="header-title">
        <a href="http://localhost:1313/">Shlok Deshmukh</a>
    </h1>

    <div class="header-menu">
        

        
        

        <p
            class="small ">
            <a href="/" >
                /home
            </a>
        </p>
        

        <p
            class="small ">
            <a href="/project" >
                /projects
            </a>
        </p>
        

        <p
            class="small ">
            <a href="/work" >
                /work
            </a>
        </p>
        
        
    </div>

    

</div>

    </header>

    <main class="main">
      







<div  class="autonumber" >
  <article>
    <header class="single-intro-container">
        
        <h1 class="single-title">Whole-body control of an aerial manipulator with reinforcement learning</h1>
        <p class="single-summary">Master Thesis</p>
        
        <div class="single-subsummary">
          
          <div>
            
            <p class="single-date">
              <time datetime="2025-08-27T00:00:00&#43;00:00">August 27, 2025</time>
            </p>
          </div>
        </div>
        
    </header>
    
    <div class="single-content">
      <p>This was my master thesis (MSc Robotics) project spanning 9 months. Click <a href="https://repository.tudelft.nl/record/uuid:c4d15d40-3b3e-463b-894f-f99955419197">here</a> to access the full thesis document.</p>
<p><strong>Problem</strong><br>
In short, the objective was to control the end-effector of an aerial manipualtor for pose-control and object manipulation. Previous work does this in a decoupled manner (sperate control of drone and manipulator), while my thesis involved implementing whole-body control leveraging reinforcement learning. The case for RL is that it learns the dynamics and handles external disturbances with minimal compute (on deployment) without needing a model, while model-based controllers (MPC, MPPI) rely on the accuracy of dervied model, which can be a non-trivial task when contact is involved.</p>
<table>
<thead>
<tr>
<th>Aerial Manipulator</th>
<th>Pose control carrying 140 g</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="/images/osprey_flying.png" alt="Point cloud reconstruction" width="424"></td>
<td><img src="/images/real-world-140g-posecontrol.png" alt="SDF from point cloud" width="600"></td>
</tr>
</tbody>
</table>
<p><strong>Contributions</strong></p>
<ul>
<li>
<p><strong>Train in simulation</strong> (<strong>Isaac Lab</strong>): Built a simulation environment modelling filters, low-level controllers and the aerial manipulator to train for end-effector pose control.</p>
</li>
<li>
<p><strong>Reward shaping</strong>: Iterated on reward functions for position/orientation accuracy, plus penalties to smooth actions and limit magnitudes to reduce oscillations.</p>
</li>
<li>
<p><strong>Control abstraction</strong>: Built a hybrid control architecture with low-level controllers (attitude/acceleration + INDI for the drone, PID for the arm) to track actions from RL trained policy.</p>
</li>
<li>
<p><strong>Deployment pipeline</strong>: Developed a end-to-end pipeline, from training to deployment. All deployment code was written in C++ and ONNX runtime was used for policy execution on a Raspberry Pi 5.</p>
</li>
</ul>
<p><strong>Results</strong></p>
<ul>
<li>
<p>Successfully trained and deployed in real-world. (<a href="https://www.youtube.com/watch?v=07ZGCPQzmG0">Video</a>)</p>
</li>
<li>
<p>The policy is able to accurately (5.3 cm, 8.8 ° error) perform end-effector pose control achieving 6-DoF commanded poses, with inferece time of <strong>0.18</strong> ms.</p>
</li>
<li>
<p>Can successfully track poses, while carrying payloads upto <strong>140 g</strong>.</p>
</li>
<li>
<p>Same policy can handle external disturbances and push a box weighing 590 g.</p>
</li>
</ul>
<p><strong>Languages and tools used:</strong> C++, Python, ROS, Isaac Sim, Gazebo</p>
<p><em>Working on this, I got to stretch my abilities, test my patience and perseverance, making it rewarding and incredibly satisfying, especially after successful real-world experiments.</em></p>

    </div>
  </article>

  

  

  
  

<div class="single-pagination">
    <hr />

    <div class="flexnowrap">

        <div class="single-pagination-prev">
            
            <div class="single-pagination-container-prev">
                <div class="single-pagination-text">←</div>
                <div class="single-pagination-text">
                    <a href="/project/fleet_auto/">
                        Fleet Autonomy for Lely Discovery Collector
                    </a>
                </div>
            </div>
            
        </div>

        <div class="single-pagination-next">
            
        </div>

    </div>

    <hr />
</div>



  

  

  
  <div class="back-to-top">
    <a href="#top">
      back to top
    </a>
  </div>
  

</div>


    </main>
  </div>

  
  





    




  <footer>
    


  </footer>

  
  <link rel="stylesheet" 
  href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css">
  
<script defer 
  src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js"></script>

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false }
      ]
    });
  });
</script>
  
</body>

<script src="/js/theme-switch.js"></script>
<script defer src="/js/copy-code.js"></script>
</html>
